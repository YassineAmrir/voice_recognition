{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model file exists at C:\\Users\\dell\\Data Science\\TensorFlow Project\\model.joblib\n",
      "‚úÖ Scaler file exists at C:\\Users\\dell\\Data Science\\TensorFlow Project\\scaler.joblib\n",
      "‚úÖ Model and Scaler loaded successfully!\n",
      "üéôÔ∏è Recording for 3 seconds...\n",
      "üì¢ Recording complete!\n",
      "‚úÖ Audio saved as output.wav\n",
      "‚úÖ Audio saved after noise reduction to output_filtered.wav\n",
      "üéß Playing back the recorded audio...\n",
      "‚úÖ Playback complete!\n",
      "üéß Playing back the filtered audio...\n",
      "‚úÖ Playback complete!\n",
      "üéâ Predicted Emotion: Crying\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import wave\n",
    "import os\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "import time\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "\n",
    "# Function to record audio from the microphone\n",
    "def record_audio(duration=5, sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Records audio from the local PC microphone for a specified duration.\n",
    "    \n",
    "    Args:\n",
    "        duration (int): Duration of the recording in seconds.\n",
    "        sample_rate (int): Sampling rate for the audio.\n",
    "        \n",
    "    Returns:\n",
    "        np.array: The recorded audio signal as a NumPy array.\n",
    "    \"\"\"\n",
    "    print(f\"üéôÔ∏è Recording for {duration} seconds...\")\n",
    "    # Record the audio, the duration * sample_rate determines the number of samples\n",
    "    recording = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype='int16')\n",
    "    sd.wait()  # Wait until the recording is finished\n",
    "    print(\"üì¢ Recording complete!\")\n",
    "    \n",
    "    # Convert the audio data to floating-point format (librosa expects float32)\n",
    "    return recording.astype(np.float32)\n",
    "\n",
    "# Function to save the recorded audio to a .wav file\n",
    "def save_audio(recording, filename='output.wav', sample_rate=16000):\n",
    "    \"\"\"\n",
    "    Saves the recorded audio to a .wav file.\n",
    "    \n",
    "    Args:\n",
    "        recording (np.array): The recorded audio signal as a NumPy array.\n",
    "        filename (str): The name of the file to save the audio.\n",
    "        sample_rate (int): Sampling rate for the audio.\n",
    "    \"\"\"\n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(1)  # Mono audio\n",
    "        wf.setsampwidth(2)  # 16-bit audio\n",
    "        wf.setframerate(sample_rate)  # Sample rate\n",
    "        wf.writeframes(recording.tobytes())  # Write the audio data to the file\n",
    "    print(f\"‚úÖ Audio saved as {filename}\")\n",
    "\n",
    "# Load the pre-trained model and scaler (using joblib here)\n",
    "model_path = r'C:\\Users\\dell\\Data Science\\TensorFlow Project\\model.joblib'\n",
    "scaler_path = r'C:\\Users\\dell\\Data Science\\TensorFlow Project\\scaler.joblib'\n",
    "\n",
    "# Check if the files exist\n",
    "if os.path.isfile(model_path):\n",
    "    print(f\"‚úÖ Model file exists at {model_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå Model file not found at {model_path}\")\n",
    "\n",
    "if os.path.isfile(scaler_path):\n",
    "    print(f\"‚úÖ Scaler file exists at {scaler_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå Scaler file not found at {scaler_path}\")\n",
    "\n",
    "# Load model and scaler\n",
    "model = joblib.load(model_path)\n",
    "scaler = joblib.load(scaler_path)\n",
    "\n",
    "print(\"‚úÖ Model and Scaler loaded successfully!\")\n",
    "\n",
    "def extract_features(filename):\n",
    "    # Load audio file with librosa\n",
    "    y, sr = librosa.load(filename, sr=None)  # sr=None to keep the original sampling rate\n",
    "    # Extract MFCCs (Mel-Frequency Cepstral Coefficients)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)  # 13 MFCC coefficients\n",
    "    # Take the mean of each coefficient (feature aggregation)\n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    return mfcc_mean\n",
    "\n",
    "\n",
    "# Function to predict emotion from the extracted features\n",
    "def predict_emotion(filename='output.wav'):\n",
    "    \"\"\"\n",
    "    Predicts if the audio is 'Crying' or 'Laughing' using the pre-trained model.\n",
    "    \n",
    "    Args:\n",
    "        audio (np.array): The raw audio signal as a NumPy array.\n",
    "        \n",
    "    Returns:\n",
    "        str: The predicted label (Crying or Laughing).\n",
    "    \"\"\"\n",
    "    # Step 1: Extract MFCC features from the audio\n",
    "    mfcc_features = extract_features(filename='output.wav')\n",
    "    \n",
    "    # Reshape the features to match the model input\n",
    "    mfcc_features = mfcc_features.reshape(1, -1)  # Ensure the shape is (1, 13)\n",
    "    \n",
    "    # Step 2: Scale the features using the loaded scaler\n",
    "    mfcc_features_scaled = scaler.transform(mfcc_features)\n",
    "    \n",
    "    # Step 3: Make predictions using the model\n",
    "    prediction = model.predict(mfcc_features_scaled)\n",
    "    \n",
    "    # Map the model's prediction to a label (Crying or Laughing)\n",
    "    predicted_label = 'Crying' if prediction[0] == 1 else 'Laughing'\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "def reduce_noise(audio_file, output_file):\n",
    "    # Load audio file\n",
    "    audio = AudioSegment.from_wav(audio_file)\n",
    "    \n",
    "    # Use a noise reduction method like this (simplified example)\n",
    "    # Here, you can play with the parameters for better results\n",
    "    audio = audio.low_pass_filter(3000)  # Remove high frequencies\n",
    "    \n",
    "    # Save the filtered audio\n",
    "    audio.export(output_file, format=\"wav\")\n",
    "    print(f\"‚úÖ Audio saved after noise reduction to {output_file}\")\n",
    "    \n",
    "# Main script\n",
    "# Record audio for 3 seconds\n",
    "audio_data = record_audio(duration=3, sample_rate=16000)\n",
    "\n",
    "# Save the recorded audio to a .wav file\n",
    "save_audio(audio_data, filename='output.wav', sample_rate=16000)\n",
    "\n",
    "# Reduce noise and save the filtered audio\n",
    "reduce_noise('output.wav', 'output_filtered.wav')\n",
    "\n",
    "# Play the original recorded audio\n",
    "print(\"üéß Playing back the recorded audio...\")\n",
    "sd.play(audio_data, samplerate=16000)\n",
    "sd.wait()  # Wait for playback to finish\n",
    "print(\"‚úÖ Playback complete!\")\n",
    "\n",
    "# Play the filtered audio\n",
    "print(\"üéß Playing back the filtered audio...\")\n",
    "filtered_audio_data, _ = librosa.load('output_filtered.wav', sr=16000)  # Load the filtered audio file\n",
    "sd.play(filtered_audio_data, samplerate=16000)  # Play the filtered audio\n",
    "sd.wait()  # Wait for playback to finish\n",
    "print(\"‚úÖ Playback complete!\")\n",
    "\n",
    "# Predict emotion from the filtered audio\n",
    "predicted_label = predict_emotion('output_filtered.wav')\n",
    "print(f\"üéâ Predicted Emotion: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
